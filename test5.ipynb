{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "# from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(sample):\n",
    "    return f\"\"\"\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{sample[\"instruction\"]}\n",
    "\n",
    "### Input:\n",
    "{sample[\"input\"]}\n",
    "\n",
    "### Response:\n",
    "{sample[\"output\"]}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "training_data = load_dataset(\"json\", data_files=\"new_dataset.json\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and tokenizer names\n",
    "base_model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "refined_model = \"test_model_simple\" #You can give it your own name\n",
    "\n",
    "# Tokenizer\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "llama_tokenizer.pad_token = llama_tokenizer.eos_token\n",
    "llama_tokenizer.padding_side = \"right\"  # Fix for fp16\n",
    "\n",
    "# Quantization Config\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=False\n",
    ")\n",
    "\n",
    "# Model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    quantization_config=quant_config,\n",
    "    device_map={\"\": 0}\n",
    ")\n",
    "base_model.config.use_cache = False\n",
    "base_model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA Config\n",
    "peft_parameters = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=8,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "# Training Params\n",
    "train_params = TrainingArguments(\n",
    "    output_dir=refined_model,\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    max_grad_norm=0.3,\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    disable_tqdm=False\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "fine_tuning = SFTTrainer(\n",
    "    model=base_model,\n",
    "    train_dataset=training_data,\n",
    "    peft_config=peft_parameters,\n",
    "    tokenizer=llama_tokenizer,\n",
    "    max_seq_length=1024,\n",
    "    packing=True,\n",
    "    formatting_func=format_prompt,\n",
    "    args=train_params\n",
    ")\n",
    "\n",
    "# Training\n",
    "fine_tuning.train()\n",
    "\n",
    "# Save Model\n",
    "fine_tuning.model.save_pretrained(refined_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.31\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl.metadata (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m526.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/aliud/anaconda3/envs/LLM/lib/python3.11/site-packages (from transformers==4.31) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/aliud/anaconda3/envs/LLM/lib/python3.11/site-packages (from transformers==4.31) (0.21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/aliud/anaconda3/envs/LLM/lib/python3.11/site-packages (from transformers==4.31) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/aliud/anaconda3/envs/LLM/lib/python3.11/site-packages (from transformers==4.31) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/aliud/anaconda3/envs/LLM/lib/python3.11/site-packages (from transformers==4.31) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/aliud/anaconda3/envs/LLM/lib/python3.11/site-packages (from transformers==4.31) (2023.12.25)\n",
      "Requirement already satisfied: requests in /home/aliud/anaconda3/envs/LLM/lib/python3.11/site-packages (from transformers==4.31) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/aliud/anaconda3/envs/LLM/lib/python3.11/site-packages (from transformers==4.31) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/aliud/anaconda3/envs/LLM/lib/python3.11/site-packages (from transformers==4.31) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/aliud/anaconda3/envs/LLM/lib/python3.11/site-packages (from transformers==4.31) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/aliud/anaconda3/envs/LLM/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/aliud/anaconda3/envs/LLM/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/aliud/anaconda3/envs/LLM/lib/python3.11/site-packages (from requests->transformers==4.31) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aliud/anaconda3/envs/LLM/lib/python3.11/site-packages (from requests->transformers==4.31) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/aliud/anaconda3/envs/LLM/lib/python3.11/site-packages (from requests->transformers==4.31) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aliud/anaconda3/envs/LLM/lib/python3.11/site-packages (from requests->transformers==4.31) (2024.2.2)\n",
      "Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.30.0\n",
      "    Uninstalling transformers-4.30.0:\n",
      "      Successfully uninstalled transformers-4.30.0\n",
      "Successfully installed transformers-4.31.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adee7a09204a44c8b99168dc9ee7bed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4371eedf7d042c0b2a3ae20c16800cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf434e8bd3f43b7a325aaaaffeef5e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.huggingface.co/repos/93/64/93644d087bcdd24640b29e7a3c92ff463e8f74a5bce00308b05b1b56faef7cc1/66dec18c9f1705b9387d62f8485f4e7d871ca388718786737ed3c72dbfaac9fb?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model-00001-of-00002.safetensors%3B+filename%3D%22model-00001-of-00002.safetensors%22%3B&Expires=1709796359&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTc5NjM1OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy85My82NC85MzY0NGQwODdiY2RkMjQ2NDBiMjllN2EzYzkyZmY0NjNlOGY3NGE1YmNlMDAzMDhiMDViMWI1NmZhZWY3Y2MxLzY2ZGVjMThjOWYxNzA1YjkzODdkNjJmODQ4NWY0ZTdkODcxY2EzODg3MTg3ODY3MzdlZDNjNzJkYmZhYWM5ZmI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=hzrm2Kff6NNCKP1uQUytd%7EUSxbg17iBQlghYVU2%7E9LL6nHUKQhyeXiiQmH0juCwlF9EL7fomomNHtpBFVGULxGGevinLbZG4n5K7IfW1hshw6mwGKv-04bUZMDc2zwc1tPF0l6T4eaOsl3vNzCAZoZ4dxxbqYnHSgPfc1ORHXgX2TzRNI4fi0Cfm1zonPtcnznwbobGVnMZVIUnlkSnp6pn6bc7anpOFEjV%7E8H2DTcZ4LoOTkIs6ONHvyUnLqa%7EPOf3-wI6-Rv3orhiQuWc23BHh%7ESVA3Cl79NdI4sEkfIGR03PQRe2UfoktbisHk7nv1YJozDDs9AdGlgC0CuJd%7EA__&Key-Pair-Id=KVTP0A1DKRTAX: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c936d6814e7c405686b844d6367c59d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   9%|8         | 860M/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09509a50ccd3415f8e1a0f11af304fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b329eb7e7bd4fdd9fa16bface6b0ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43132c98db04d89aaa600288827eb64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/179 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load finetuned LLM model and tokenizer\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    'simple_model/checkpoint-60',\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained('simple_model/checkpoint-60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69dcf2711d3d497f962a6b41524b6715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/home/aliud/anaconda3/envs/LLM/lib/python3.11/site-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n",
      "/home/aliud/anaconda3/envs/LLM/lib/python3.11/site-packages/bitsandbytes/nn/modules.py:226: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction:\n",
      "You should generate XML to perform actions using these tags: task, action, actionType, object, location. Coordinates of locations: table, bed, fridge, oven, door, window\n",
      "\n",
      "Input:\n",
      "Move a laptop from the table to the bed.\n",
      "\n",
      "Generated Response:\n",
      "<task><action><actionType>GO</actionType><location>oven</location></action><action><actionType>TAKE</actionType><object>hot tea</object><location>oven</location></action><action><actionType>GO</actionType><location>table</location></action><action><actionType>PUT</actionType><object>hot tea</object><location>table</location></action><action><actionType>GO</actionType><location>HOME</location></action></task>\n",
      "\n",
      "\n",
      "Ground Truth:\n",
      "<task><action><actionType>GO</actionType><location>table</location></action><action><actionType>TAKE</actionType><object>laptop</object><location>table</location></action><action><actionType>GO</actionType><location>bed</location></action><action><actionType>PUT</actionType><object>laptop</object><location>bed</location></action><action><actionType>GO</actionType><location>HOME</location></action></task>\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from random import randrange\n",
    "\n",
    "# Load dataset from the hub\n",
    "dataset = load_dataset(\"json\", data_files=\"new_dataset.json\", split=\"train\")\n",
    "sample = dataset[randrange(len(dataset))]\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{sample[\"instruction\"]}\n",
    "\n",
    "### Input:\n",
    "{\"I am at the bed, bring me hot tea from oven\"}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True).input_ids.cuda()\n",
    "outputs = model.generate(input_ids=input_ids, max_new_tokens=512, do_sample=True, top_p=0.6,temperature=0.9)\n",
    "\n",
    "print(f\"Instruction:\\n{sample['instruction']}\\n\")\n",
    "print(f\"Input:\\n{sample['input']}\\n\")\n",
    "print(f\"Generated Response:\\n{tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0][len(prompt):]}\\n\")\n",
    "print(f\"Ground Truth:\\n{sample['output']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{sample[\"instruction\"]}\n",
    "\n",
    "### Input:\n",
    "`i'm in the kitchen. Take chocolate from fridge and wash dishes.\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True).input_ids.cuda()\n",
    "outputs = model.generate(input_ids=input_ids, max_new_tokens=512, do_sample=True, top_p=0.6,temperature=0.9)\n",
    "\n",
    "print(f\"Instruction:\\n{sample['instruction']}\\n\")\n",
    "print(f\"Input:\\n{sample['input']}\\n\")\n",
    "print(f\"Generated Response:\\n{tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0][len(prompt):]}\\n\")\n",
    "print(f\"Ground Truth:\\n{sample['output']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse = load_dataset(\"json\", data_files=\"dataset copy.json\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ET.tostring(root, encoding='utf8').split()[-1].decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sample(locations, obj):\n",
    "    return f'<task><action><actionType>GO</actionType><location>{locations[0]}</location></action><action><actionType>TAKE</actionType><object>{obj}</object><location>{locations[0]}</location></action><action><actionType>GO</actionType><location>{locations[1]}</location></action><action><actionType>PUT</actionType><object>{obj}</object><location>{locations[1]}</location></action><action><actionType>GO</actionType><location>HOME</location></action></task>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(parse)):\n",
    "    sample = {}\n",
    "    sample['instruction'] = parse[i]['instruction']\n",
    "    sample['input'] = parse[i]['input']\n",
    "    tree = ET.ElementTree(ET.fromstring(parse[i]['output']))\n",
    "    root = tree.getroot()\n",
    "    locations = []\n",
    "    obj = ''\n",
    "    for j in range(len(root)):\n",
    "        if root[j][0].text != 'GO':\n",
    "            obj = root[j][1].text\n",
    "            locations.append(root[j][2].text)\n",
    "    sample['output'] = to_sample(locations, obj)\n",
    "    new_dataset.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_sample(locations, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"new_dataset.json\", \"w\") as outfile: \n",
    "    json.dump(new_dataset, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dataset(\"json\", data_files=\"new_dataset.json\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<task><action><actionType>GO</actionType><location>oven</location></action><action><actionType>TAKE</actionType><object>hot tea</object><location>oven</location></action><action><actionType>GO</actionType><location>table</location></action><action><actionType>PUT</actionType><object>hot tea</object><location>table</location></action><action><actionType>GO</actionType><location>HOME</location></action></task>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task = 'I am at the bed, bring me hot tea from oven'\n",
    "f\"\"\"\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "You should generate XML to perform actions using these tags: task, action, actionType, object, location. Coordinates of locations: table, bed, fridge, oven, door, window\", \"input\": \"Move a glass from the table to the fridge.\n",
    "\n",
    "### Input:\n",
    "{task}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True).input_ids.cuda()\n",
    "outputs = model.generate(input_ids=input_ids, max_new_tokens=512, do_sample=True, top_p=0.6,temperature=0.9)\n",
    "\n",
    "print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0][len(prompt):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "def parse_xml(bt):\n",
    "    tree = ET.ElementTree(ET.fromstring(bt))\n",
    "    root = tree.getroot()\n",
    "    for child in root:\n",
    "        print(child[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO\n",
      "TAKE\n",
      "GO\n",
      "PUT\n",
      "GO\n"
     ]
    }
   ],
   "source": [
    "parse_xml('<task><action><actionType>GO</actionType><location>oven</location></action><action><actionType>TAKE</actionType><object>hot tea</object><location>oven</location></action><action><actionType>GO</actionType><location>table</location></action><action><actionType>PUT</actionType><object>hot tea</object><location>table</location></action><action><actionType>GO</actionType><location>HOME</location></action></task>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<task>\n",
      "    <action>\n",
      "        <actionType>\n",
      "            GO\n",
      "        </actionType>\n",
      "        <location>\n",
      "            oven\n",
      "        </location>\n",
      "    </action>\n",
      "    <action>\n",
      "        <actionType>\n",
      "            TAKE\n",
      "        </actionType>\n",
      "        <object>\n",
      "            hot tea\n",
      "        </object>\n",
      "        <location>\n",
      "            oven\n",
      "        </location>\n",
      "    </action>\n",
      "    <action>\n",
      "        <actionType>\n",
      "            GO\n",
      "        </actionType>\n",
      "        <location>\n",
      "            table\n",
      "        </location>\n",
      "    </action>\n",
      "    <action>\n",
      "        <actionType>\n",
      "            PUT\n",
      "        </actionType>\n",
      "        <object>\n",
      "            hot tea\n",
      "        </object>\n",
      "        <location>\n",
      "            table\n",
      "        </location>\n",
      "    </action>\n",
      "    <action>\n",
      "        <actionType>\n",
      "            GO\n",
      "        </actionType>\n",
      "        <location>\n",
      "            HOME\n",
      "        </location>\n",
      "    </action>\n",
      "</task>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "input_string = '<task><action><actionType>GO</actionType><location>oven</location></action><action><actionType>TAKE</actionType><object>hot tea</object><location>oven</location></action><action><actionType>GO</actionType><location>table</location></action><action><actionType>PUT</actionType><object>hot tea</object><location>table</location></action><action><actionType>GO</actionType><location>HOME</location></action></task>'\n",
    "\n",
    "# Parse the input string into an ElementTree\n",
    "root = ET.fromstring(input_string)\n",
    "\n",
    "# Function to recursively format the ElementTree with specific indentation\n",
    "def format_element(element, level=0):\n",
    "    indent = '    ' * level\n",
    "    result = f'{indent}<{element.tag}>\\n'\n",
    "\n",
    "    for child in element:\n",
    "        result += format_element(child, level + 1)\n",
    "\n",
    "    if element.text and element.text.strip():\n",
    "        result += f'{indent}    {element.text.strip()}\\n'\n",
    "\n",
    "    result += f'{indent}</{element.tag}>\\n'\n",
    "    return result\n",
    "\n",
    "# Format the ElementTree with specific indentation\n",
    "formatted_string = format_element(root)\n",
    "\n",
    "# Display the collected string\n",
    "print(formatted_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<task>\n",
      "    <action>\n",
      "        <actionType>GO        </actionType>\n",
      "        <location>oven        </location>\n",
      "    </action>\n",
      "    <action>\n",
      "        <actionType>TAKE        </actionType>\n",
      "        <object>hot tea        </object>\n",
      "        <location>oven        </location>\n",
      "    </action>\n",
      "    <action>\n",
      "        <actionType>GO        </actionType>\n",
      "        <location>table        </location>\n",
      "    </action>\n",
      "    <action>\n",
      "        <actionType>PUT        </actionType>\n",
      "        <object>hot tea        </object>\n",
      "        <location>table        </location>\n",
      "    </action>\n",
      "    <action>\n",
      "        <actionType>GO        </actionType>\n",
      "        <location>HOME        </location>\n",
      "    </action>\n",
      "</task>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "input_string = '<task><action><actionType>GO</actionType><location>oven</location></action><action><actionType>TAKE</actionType><object>hot tea</object><location>oven</location></action><action><actionType>GO</actionType><location>table</location></action><action><actionType>PUT</actionType><object>hot tea</object><location>table</location></action><action><actionType>GO</actionType><location>HOME</location></action></task>'\n",
    "\n",
    "# Parse the input string into an ElementTree\n",
    "root = ET.fromstring(input_string)\n",
    "\n",
    "# Function to recursively format the ElementTree with opening tag and text on the same line\n",
    "def format_element(element, level=0):\n",
    "    indent = '    ' * level\n",
    "    if element.text is not None and element.text.strip():\n",
    "        result = f'{indent}<{element.tag}>{element.text.strip()}'\n",
    "    else:\n",
    "        result = f'{indent}<{element.tag}>\\n'\n",
    "\n",
    "    for child in element:\n",
    "        result += format_element(child, level + 1)\n",
    "\n",
    "    result += f'{indent}</{element.tag}>\\n'\n",
    "    return result\n",
    "\n",
    "# Format the ElementTree with opening tag and text on the same line\n",
    "formatted_string = format_element(root)\n",
    "\n",
    "# Display the collected string\n",
    "print(formatted_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=300x500>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "    \n",
    "# Reading an image in default mode \n",
    "image = np.ones((500, 300), dtype = np.uint8) * 255\n",
    "    \n",
    "# Window name in which image is displayed \n",
    "window_name = 'Image'\n",
    "  \n",
    "# font \n",
    "font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "  \n",
    "# org \n",
    "org = (0, 20) \n",
    "  \n",
    "# fontScale \n",
    "fontScale = 0.1\n",
    "   \n",
    "# Blue color in BGR \n",
    "color = (0) \n",
    "  \n",
    "# Line thickness of 2 px \n",
    "thickness = 2\n",
    "   \n",
    "# Using cv2.putText() method \n",
    "image = cv2.putText(image, formatted_string, org, font,  \n",
    "                   fontScale, color, thickness, cv2.LINE_AA) \n",
    "\n",
    "Image.fromarray(image)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASwAAAH0CAAAAACie0/rAAACqElEQVR4Ae3QMQEAAADCoPVPbQo/iEBhwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMPAYGTAIAAWirYBgAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=300x500>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(np.zeros((500, 300), dtype = np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
